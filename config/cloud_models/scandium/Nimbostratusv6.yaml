data:
  dataset_path: '../data'
  csv_name: 'train_cloudy.csv'
  grid_augmentation: false
dataloader:
  num_workers: 6
  batch_size: 16
  shuffle: true
  prefetch_factor: 2
model:
  base_model_to_load: "../models/scandium/295789/295789_last.pth"
  s1_layers:
    out_channels: 2 # [in_dim, out_dim]
    kernel_size: 5 # [in_dim, out_dim]
  mask_layer:
    out_channels: 2 # [in_dim, out_dim]
    kernel_size: 3 # [in_dim, out_dim]
  conv_block_lai:
    channels: [24, 12, 1]  # number of conv layers is len(channels)
    kernel_sizes: [7, 7, 7]
    recursions: 6
  conv_block_mask:
    channels: [24, 12, 6]  # number of conv layers is len(channels)
    kernel_sizes: [5, 5, 5, 5]
base_model:
  s1_ae_config:  # U-Net-like architecture
    in_dim: 2  # always 2 (if input={VV, VH})
    out_dim: 1
    layer_channels: [16, 32, 64]
    conv_per_layer: 1
    residual: false
  mask_module_dim: [6, 2]  # include input dim
  glob_module_dims: [2, 8, 2]  # include input dim
  conv_block_dims: [32, 64, 128]  # exclude input dim (automatically inferred)
train:
  learning_rate: 0.0005
  learning_rate_n_mult: 2  # number of times to decay lr (evenly spaced during the full training)
  learning_rate_decay: 0.2  # lr *= decay at each decay step
  n_epochs: 120
  log_interval: 5  # in iterations
  save_interval: 60  # in epochs
  interm_supervis: false  # intermediate supervision for AE
